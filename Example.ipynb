{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caee6449",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, input_dim=9, hidden_dim=7, latent_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build encoder and decoder\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        \n",
    "    def build_encoder(self):\n",
    "        \"\"\"Build the encoder network: input(9) -> hidden(7) -> latent(2)\"\"\"\n",
    "        inputs = keras.Input(shape=(self.input_dim,))\n",
    "        \n",
    "        # Hidden layer\n",
    "        hidden = layers.Dense(self.hidden_dim, activation=\"relu\")(inputs)\n",
    "        \n",
    "        # Mean and log variance for latent space\n",
    "        z_mean = layers.Dense(self.latent_dim, name=\"z_mean\")(hidden)\n",
    "        z_log_var = layers.Dense(self.latent_dim, name=\"z_log_var\")(hidden)\n",
    "        \n",
    "        return keras.Model(inputs, [z_mean, z_log_var], name=\"encoder\")\n",
    "    \n",
    "    def build_decoder(self):\n",
    "        \"\"\"Build the decoder network: latent(2) -> hidden(7) -> output(9)\"\"\"\n",
    "        latent_inputs = keras.Input(shape=(self.latent_dim,))\n",
    "        \n",
    "        # Hidden layer\n",
    "        hidden = layers.Dense(self.hidden_dim, activation=\"relu\")(latent_inputs)\n",
    "        \n",
    "        # Output layer (sigmoid for values between 0 and 1)\n",
    "        outputs = layers.Dense(self.input_dim, activation=\"sigmoid\")(hidden)\n",
    "        \n",
    "        return keras.Model(latent_inputs, outputs, name=\"decoder\")\n",
    "    \n",
    "    def reparameterize(self, z_mean, z_log_var):\n",
    "        \"\"\"Reparameterization trick: sample from N(mu, sigma) using N(0,1)\"\"\"\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        epsilon = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass through the VAE\"\"\"\n",
    "        z_mean, z_log_var = self.encoder(inputs)\n",
    "        z = self.reparameterize(z_mean, z_log_var)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, z_mean, z_log_var\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent space\"\"\"\n",
    "        z_mean, z_log_var = self.encoder(x)\n",
    "        return self.reparameterize(z_mean, z_log_var)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode from latent space\"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "class VAETrainer:\n",
    "    def __init__(self, vae, optimizer=None):\n",
    "        self.vae = vae\n",
    "        self.optimizer = optimizer or keras.optimizers.Adam(1e-3)\n",
    "        \n",
    "        # Metrics\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    def compute_loss(self, x):\n",
    "        \"\"\"Compute VAE loss: reconstruction loss + KL divergence\"\"\"\n",
    "        reconstructed, z_mean, z_log_var = self.vae(x)\n",
    "        \n",
    "        # Reconstruction loss (mean squared error for continuous data)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(tf.square(x - reconstructed), axis=1)\n",
    "        )\n",
    "        \n",
    "        # KL divergence loss\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return total_loss, reconstruction_loss, kl_loss\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, x):\n",
    "        \"\"\"Single training step\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, reconstruction_loss, kl_loss = self.compute_loss(x)\n",
    "        \n",
    "        gradients = tape.gradient(total_loss, self.vae.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.vae.trainable_variables))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def train(self, dataset, epochs=100, verbose=1):\n",
    "        \"\"\"Train the VAE\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            # Reset metrics\n",
    "            self.total_loss_tracker.reset_states()\n",
    "            self.reconstruction_loss_tracker.reset_states()\n",
    "            self.kl_loss_tracker.reset_states()\n",
    "            \n",
    "            # Training loop\n",
    "            for step, x_batch in enumerate(dataset):\n",
    "                metrics = self.train_step(x_batch)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "                print(f\"Loss: {metrics['loss']:.4f}, \"\n",
    "                      f\"Reconstruction: {metrics['reconstruction_loss']:.4f}, \"\n",
    "                      f\"KL: {metrics['kl_loss']:.4f}\")\n",
    "\n",
    "def generate_synthetic_data(n_samples=1000):\n",
    "    \"\"\"Generate synthetic 9-dimensional data for demonstration\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create two clusters in 9D space\n",
    "    cluster1 = np.random.multivariate_normal(\n",
    "        mean=[0.3, 0.7, 0.2, 0.8, 0.1, 0.9, 0.4, 0.6, 0.5],\n",
    "        cov=np.eye(9) * 0.05,\n",
    "        size=n_samples // 2\n",
    "    )\n",
    "    \n",
    "    cluster2 = np.random.multivariate_normal(\n",
    "        mean=[0.8, 0.2, 0.9, 0.1, 0.7, 0.3, 0.6, 0.4, 0.5],\n",
    "        cov=np.eye(9) * 0.05,\n",
    "        size=n_samples // 2\n",
    "    )\n",
    "    \n",
    "    # Combine and normalize to [0, 1]\n",
    "    data = np.vstack([cluster1, cluster2])\n",
    "    data = np.clip(data, 0, 1)  # Ensure values are in [0, 1]\n",
    "    \n",
    "    # Create labels for visualization\n",
    "    labels = np.concatenate([np.zeros(n_samples // 2), np.ones(n_samples // 2)])\n",
    "    \n",
    "    return data.astype(np.float32), labels.astype(int)\n",
    "\n",
    "def plot_latent_space(vae, data, labels=None, title=\"Latent Space Representation\"):\n",
    "    \"\"\"Plot the 2D latent space representation\"\"\"\n",
    "    # Encode to latent space\n",
    "    z_mean, _ = vae.encoder(data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if labels is not None:\n",
    "        scatter = plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels, cmap='viridis', alpha=0.6)\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "    else:\n",
    "        plt.scatter(z_mean[:, 0], z_mean[:, 1], alpha=0.6)\n",
    "    \n",
    "    plt.xlabel(\"Latent Dimension 1\")\n",
    "    plt.ylabel(\"Latent Dimension 2\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def plot_reconstructions(vae, data, n_samples=5):\n",
    "    \"\"\"Plot original vs reconstructed vectors\"\"\"\n",
    "    indices = np.random.choice(len(data), n_samples, replace=False)\n",
    "    x_sample = data[indices]\n",
    "    reconstructions, _, _ = vae(x_sample)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Original\n",
    "        axes[0, i].bar(range(9), x_sample[i])\n",
    "        axes[0, i].set_title(f\"Original {i+1}\")\n",
    "        axes[0, i].set_ylim(0, 1)\n",
    "        axes[0, i].set_xticks(range(9))\n",
    "        \n",
    "        # Reconstruction\n",
    "        axes[1, i].bar(range(9), reconstructions[i])\n",
    "        axes[1, i].set_title(f\"Reconstructed {i+1}\")\n",
    "        axes[1, i].set_ylim(0, 1)\n",
    "        axes[1, i].set_xticks(range(9))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_generated_samples(vae, n_samples=5):\n",
    "    \"\"\"Generate and plot new samples from random latent vectors\"\"\"\n",
    "    # Sample random points in latent space\n",
    "    random_latent = tf.random.normal(shape=(n_samples, vae.latent_dim))\n",
    "    generated_samples = vae.decode(random_latent)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(1, n_samples, i + 1)\n",
    "        plt.bar(range(9), generated_samples[i])\n",
    "        plt.title(f\"Generated {i+1}\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xticks(range(9))\n",
    "    \n",
    "    plt.suptitle(\"Generated Samples from Random Latent Vectors\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def interpolate_in_latent_space(vae, data, n_steps=5):\n",
    "    \"\"\"Interpolate between two points in latent space\"\"\"\n",
    "    # Get two random samples\n",
    "    indices = np.random.choice(len(data), 2, replace=False)\n",
    "    x1, x2 = data[indices[0]:indices[0]+1], data[indices[1]:indices[1]+1]\n",
    "    \n",
    "    # Encode to latent space\n",
    "    z1_mean, _ = vae.encoder(x1)\n",
    "    z2_mean, _ = vae.encoder(x2)\n",
    "    \n",
    "    # Interpolate\n",
    "    alphas = np.linspace(0, 1, n_steps)\n",
    "    interpolated_z = []\n",
    "    for alpha in alphas:\n",
    "        z_interp = (1 - alpha) * z1_mean + alpha * z2_mean\n",
    "        interpolated_z.append(z_interp)\n",
    "    \n",
    "    interpolated_z = tf.concat(interpolated_z, axis=0)\n",
    "    interpolated_samples = vae.decode(interpolated_z)\n",
    "    \n",
    "    # Plot interpolation\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i in range(n_steps):\n",
    "        plt.subplot(1, n_steps, i + 1)\n",
    "        plt.bar(range(9), interpolated_samples[i])\n",
    "        plt.title(f\"α = {alphas[i]:.2f}\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xticks(range(9))\n",
    "    \n",
    "    plt.suptitle(\"Latent Space Interpolation\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_model_summary(vae):\n",
    "    \"\"\"Print model architecture summary\"\"\"\n",
    "    print(\"VAE Architecture:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Input dimension: {vae.input_dim}\")\n",
    "    print(f\"Hidden dimension: {vae.hidden_dim}\")\n",
    "    print(f\"Latent dimension: {vae.latent_dim}\")\n",
    "    print(\"\\nEncoder:\")\n",
    "    vae.encoder.summary()\n",
    "    print(\"\\nDecoder:\")\n",
    "    vae.decoder.summary()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate synthetic data\n",
    "    print(\"Generating synthetic 9D data...\")\n",
    "    data, labels = generate_synthetic_data(n_samples=2000)\n",
    "    \n",
    "    # Split into train/test\n",
    "    train_size = int(0.8 * len(data))\n",
    "    x_train, x_test = data[:train_size], data[train_size:]\n",
    "    y_train, y_test = labels[:train_size], labels[train_size:]\n",
    "    \n",
    "    # Create dataset\n",
    "    batch_size = 64\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "    \n",
    "    # Create VAE\n",
    "    vae = VAE(input_dim=9, hidden_dim=7, latent_dim=2)\n",
    "    print_model_summary(vae)\n",
    "    \n",
    "    # Train VAE\n",
    "    trainer = VAETrainer(vae)\n",
    "    print(\"\\nTraining VAE...\")\n",
    "    trainer.train(train_dataset, epochs=100)\n",
    "    \n",
    "    # Visualizations\n",
    "    print(\"\\nPlotting reconstructions...\")\n",
    "    plot_reconstructions(vae, x_test)\n",
    "    \n",
    "    print(\"Plotting generated samples...\")\n",
    "    plot_generated_samples(vae)\n",
    "    \n",
    "    print(\"Plotting latent space...\")\n",
    "    plot_latent_space(vae, x_test, y_test)\n",
    "    \n",
    "    print(\"Plotting latent space interpolation...\")\n",
    "    interpolate_in_latent_space(vae, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, latent_dim=32, input_shape=(28, 28, 1)):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Build encoder and decoder\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        \n",
    "    def build_encoder(self):\n",
    "        \"\"\"Build the encoder network\"\"\"\n",
    "        inputs = keras.Input(shape=self.input_shape)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(inputs)\n",
    "        x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(16, activation=\"relu\")(x)\n",
    "        \n",
    "        # Mean and log variance for latent space\n",
    "        z_mean = layers.Dense(self.latent_dim, name=\"z_mean\")(x)\n",
    "        z_log_var = layers.Dense(self.latent_dim, name=\"z_log_var\")(x)\n",
    "        \n",
    "        return keras.Model(inputs, [z_mean, z_log_var], name=\"encoder\")\n",
    "    \n",
    "    def build_decoder(self):\n",
    "        \"\"\"Build the decoder network\"\"\"\n",
    "        latent_inputs = keras.Input(shape=(self.latent_dim,))\n",
    "        x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "        x = layers.Reshape((7, 7, 64))(x)\n",
    "        \n",
    "        # Transpose convolutional layers\n",
    "        x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "        \n",
    "        # Output layer\n",
    "        decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "        \n",
    "        return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    \n",
    "    def reparameterize(self, z_mean, z_log_var):\n",
    "        \"\"\"Reparameterization trick: sample from N(mu, sigma) using N(0,1)\"\"\"\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        epsilon = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass through the VAE\"\"\"\n",
    "        z_mean, z_log_var = self.encoder(inputs)\n",
    "        z = self.reparameterize(z_mean, z_log_var)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, z_mean, z_log_var\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent space\"\"\"\n",
    "        z_mean, z_log_var = self.encoder(x)\n",
    "        return self.reparameterize(z_mean, z_log_var)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode from latent space\"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "class VAETrainer:\n",
    "    def __init__(self, vae, optimizer=None):\n",
    "        self.vae = vae\n",
    "        self.optimizer = optimizer or keras.optimizers.Adam(1e-4)\n",
    "        \n",
    "        # Metrics\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    def compute_loss(self, x):\n",
    "        \"\"\"Compute VAE loss: reconstruction loss + KL divergence\"\"\"\n",
    "        reconstructed, z_mean, z_log_var = self.vae(x)\n",
    "        \n",
    "        # Reconstruction loss (binary crossentropy)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.binary_crossentropy(x, reconstructed), axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # KL divergence loss\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return total_loss, reconstruction_loss, kl_loss\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, x):\n",
    "        \"\"\"Single training step\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, reconstruction_loss, kl_loss = self.compute_loss(x)\n",
    "        \n",
    "        gradients = tape.gradient(total_loss, self.vae.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.vae.trainable_variables))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def train(self, dataset, epochs=10, verbose=1):\n",
    "        \"\"\"Train the VAE\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            # Reset metrics\n",
    "            self.total_loss_tracker.reset_states()\n",
    "            self.reconstruction_loss_tracker.reset_states()\n",
    "            self.kl_loss_tracker.reset_states()\n",
    "            \n",
    "            # Training loop\n",
    "            for step, x_batch in enumerate(dataset):\n",
    "                metrics = self.train_step(x_batch)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "                print(f\"Loss: {metrics['loss']:.4f}, \"\n",
    "                      f\"Reconstruction: {metrics['reconstruction_loss']:.4f}, \"\n",
    "                      f\"KL: {metrics['kl_loss']:.4f}\")\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Load and preprocess MNIST dataset\"\"\"\n",
    "    (x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Normalize to [0, 1] and add channel dimension\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    \n",
    "    return x_train, x_test\n",
    "\n",
    "def plot_latent_space(vae, x_test, y_test=None, n_samples=1000):\n",
    "    \"\"\"Plot the latent space representation\"\"\"\n",
    "    # Sample subset of test data\n",
    "    indices = np.random.choice(len(x_test), n_samples, replace=False)\n",
    "    x_sample = x_test[indices]\n",
    "    \n",
    "    # Encode to latent space\n",
    "    z_mean, _ = vae.encoder(x_sample)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if y_test is not None:\n",
    "        y_sample = y_test[indices]\n",
    "        scatter = plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_sample, cmap='tab10', alpha=0.6)\n",
    "        plt.colorbar(scatter)\n",
    "    else:\n",
    "        plt.scatter(z_mean[:, 0], z_mean[:, 1], alpha=0.6)\n",
    "    \n",
    "    plt.xlabel(\"Latent Dimension 1\")\n",
    "    plt.ylabel(\"Latent Dimension 2\")\n",
    "    plt.title(\"Latent Space Representation\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_generated_images(vae, n_samples=10):\n",
    "    \"\"\"Generate and plot new images from random latent vectors\"\"\"\n",
    "    # Sample random points in latent space\n",
    "    random_latent = tf.random.normal(shape=(n_samples, vae.latent_dim))\n",
    "    generated_images = vae.decode(random_latent)\n",
    "    \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(1, n_samples, i + 1)\n",
    "        plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Generated Images from Random Latent Vectors\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_reconstructions(vae, x_test, n_samples=10):\n",
    "    \"\"\"Plot original vs reconstructed images\"\"\"\n",
    "    indices = np.random.choice(len(x_test), n_samples, replace=False)\n",
    "    x_sample = x_test[indices]\n",
    "    reconstructions, _, _ = vae(x_sample)\n",
    "    \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n_samples):\n",
    "        # Original\n",
    "        ax = plt.subplot(2, n_samples, i + 1)\n",
    "        plt.imshow(x_sample[i, :, :, 0], cmap='gray')\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Reconstruction\n",
    "        ax = plt.subplot(2, n_samples, i + 1 + n_samples)\n",
    "        plt.imshow(reconstructions[i, :, :, 0], cmap='gray')\n",
    "        plt.title(\"Reconstructed\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    x_train, x_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Create dataset\n",
    "    batch_size = 128\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    \n",
    "    # Create and train VAE\n",
    "    vae = VAE(latent_dim=2)  # 2D latent space for visualization\n",
    "    trainer = VAETrainer(vae)\n",
    "    \n",
    "    print(\"Training VAE...\")\n",
    "    trainer.train(train_dataset, epochs=10)\n",
    "    \n",
    "    # Visualizations\n",
    "    print(\"Plotting reconstructions...\")\n",
    "    plot_reconstructions(vae, x_test)\n",
    "    \n",
    "    print(\"Plotting generated images...\")\n",
    "    plot_generated_images(vae)\n",
    "    \n",
    "    # Load labels for latent space visualization\n",
    "    (_, y_train), (_, y_test) = keras.datasets.mnist.load_data()\n",
    "    print(\"Plotting latent space...\")\n",
    "    plot_latent_space(vae, x_test, y_test)b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58dd784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class CVAE(keras.Model):\n",
    "    def __init__(self, input_dim=9, hidden_dim=7, latent_dim=2, num_classes=3):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Build encoder and decoder\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        \n",
    "    def build_encoder(self):\n",
    "        \"\"\"Build the conditional encoder network: input(9) + condition(num_classes) -> hidden(7) -> latent(2)\"\"\"\n",
    "        # Input data\n",
    "        data_inputs = keras.Input(shape=(self.input_dim,), name=\"data_input\")\n",
    "        \n",
    "        # Condition input (one-hot encoded)\n",
    "        condition_inputs = keras.Input(shape=(self.num_classes,), name=\"condition_input\")\n",
    "        \n",
    "        # Concatenate data and condition\n",
    "        combined = layers.Concatenate()([data_inputs, condition_inputs])\n",
    "        \n",
    "        # Hidden layer\n",
    "        hidden = layers.Dense(self.hidden_dim, activation=\"relu\")(combined)\n",
    "        \n",
    "        # Mean and log variance for latent space\n",
    "        z_mean = layers.Dense(self.latent_dim, name=\"z_mean\")(hidden)\n",
    "        z_log_var = layers.Dense(self.latent_dim, name=\"z_log_var\")(hidden)\n",
    "        \n",
    "        return keras.Model([data_inputs, condition_inputs], [z_mean, z_log_var], name=\"encoder\")\n",
    "    \n",
    "    def build_decoder(self):\n",
    "        \"\"\"Build the conditional decoder network: latent(2) + condition(num_classes) -> hidden(7) -> output(9)\"\"\"\n",
    "        # Latent input\n",
    "        latent_inputs = keras.Input(shape=(self.latent_dim,), name=\"latent_input\")\n",
    "        \n",
    "        # Condition input (one-hot encoded)\n",
    "        condition_inputs = keras.Input(shape=(self.num_classes,), name=\"condition_input\")\n",
    "        \n",
    "        # Concatenate latent and condition\n",
    "        combined = layers.Concatenate()([latent_inputs, condition_inputs])\n",
    "        \n",
    "        # Hidden layer\n",
    "        hidden = layers.Dense(self.hidden_dim, activation=\"relu\")(combined)\n",
    "        \n",
    "        # Output layer (sigmoid for values between 0 and 1)\n",
    "        outputs = layers.Dense(self.input_dim, activation=\"sigmoid\")(hidden)\n",
    "        \n",
    "        return keras.Model([latent_inputs, condition_inputs], outputs, name=\"decoder\")\n",
    "    \n",
    "    def reparameterize(self, z_mean, z_log_var):\n",
    "        \"\"\"Reparameterization trick: sample from N(mu, sigma) using N(0,1)\"\"\"\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        epsilon = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass through the CVAE\"\"\"\n",
    "        data, conditions = inputs\n",
    "        z_mean, z_log_var = self.encoder([data, conditions])\n",
    "        z = self.reparameterize(z_mean, z_log_var)\n",
    "        reconstructed = self.decoder([z, conditions])\n",
    "        return reconstructed, z_mean, z_log_var\n",
    "    \n",
    "    def encode(self, data, conditions):\n",
    "        \"\"\"Encode input to latent space\"\"\"\n",
    "        z_mean, z_log_var = self.encoder([data, conditions])\n",
    "        return self.reparameterize(z_mean, z_log_var)\n",
    "    \n",
    "    def decode(self, z, conditions):\n",
    "        \"\"\"Decode from latent space\"\"\"\n",
    "        return self.decoder([z, conditions])\n",
    "\n",
    "class CVAETrainer:\n",
    "    def __init__(self, cvae, optimizer=None):\n",
    "        self.cvae = cvae\n",
    "        self.optimizer = optimizer or keras.optimizers.Adam(1e-3)\n",
    "        \n",
    "        # Metrics\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    def compute_loss(self, data, conditions):\n",
    "        \"\"\"Compute CVAE loss: reconstruction loss + KL divergence\"\"\"\n",
    "        reconstructed, z_mean, z_log_var = self.cvae([data, conditions])\n",
    "        \n",
    "        # Reconstruction loss (mean squared error for continuous data)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(tf.square(data - reconstructed), axis=1)\n",
    "        )\n",
    "        \n",
    "        # KL divergence loss\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return total_loss, reconstruction_loss, kl_loss\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data, conditions):\n",
    "        \"\"\"Single training step\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, reconstruction_loss, kl_loss = self.compute_loss(data, conditions)\n",
    "        \n",
    "        gradients = tape.gradient(total_loss, self.cvae.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.cvae.trainable_variables))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def train(self, dataset, epochs=100, verbose=1):\n",
    "        \"\"\"Train the CVAE\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            # Reset metrics\n",
    "            self.total_loss_tracker.reset_states()\n",
    "            self.reconstruction_loss_tracker.reset_states()\n",
    "            self.kl_loss_tracker.reset_states()\n",
    "            \n",
    "            # Training loop\n",
    "            for step, (data_batch, condition_batch) in enumerate(dataset):\n",
    "                metrics = self.train_step(data_batch, condition_batch)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "                print(f\"Loss: {metrics['loss']:.4f}, \"\n",
    "                      f\"Reconstruction: {metrics['reconstruction_loss']:.4f}, \"\n",
    "                      f\"KL: {metrics['kl_loss']:.4f}\")\n",
    "\n",
    "def generate_conditional_synthetic_data(n_samples=1500, num_classes=3):\n",
    "    \"\"\"Generate synthetic 9-dimensional data with different conditions/classes\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # Define different patterns for each class\n",
    "    class_patterns = [\n",
    "        # Class 0: Low values pattern\n",
    "        {\"mean\": [0.2, 0.3, 0.1, 0.4, 0.2, 0.3, 0.1, 0.2, 0.3], \"cov\": 0.03},\n",
    "        # Class 1: Medium values pattern  \n",
    "        {\"mean\": [0.5, 0.6, 0.4, 0.7, 0.5, 0.6, 0.4, 0.5, 0.6], \"cov\": 0.03},\n",
    "        # Class 2: High values pattern\n",
    "        {\"mean\": [0.8, 0.7, 0.9, 0.6, 0.8, 0.7, 0.9, 0.8, 0.7], \"cov\": 0.03}\n",
    "    ]\n",
    "    \n",
    "    samples_per_class = n_samples // num_classes\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        pattern = class_patterns[class_id]\n",
    "        \n",
    "        class_data = np.random.multivariate_normal(\n",
    "            mean=pattern[\"mean\"],\n",
    "            cov=np.eye(9) * pattern[\"cov\"],\n",
    "            size=samples_per_class\n",
    "        )\n",
    "        \n",
    "        # Clip to [0, 1] range\n",
    "        class_data = np.clip(class_data, 0, 1)\n",
    "        \n",
    "        data_list.append(class_data)\n",
    "        labels_list.append(np.full(samples_per_class, class_id))\n",
    "    \n",
    "    # Combine all classes\n",
    "    data = np.vstack(data_list).astype(np.float32)\n",
    "    labels = np.concatenate(labels_list).astype(int)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    indices = np.random.permutation(len(data))\n",
    "    data = data[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "def labels_to_onehot(labels, num_classes):\n",
    "    \"\"\"Convert integer labels to one-hot encoding\"\"\"\n",
    "    return tf.one_hot(labels, num_classes)\n",
    "\n",
    "def plot_conditional_latent_space(cvae, data, labels, title=\"Conditional Latent Space\"):\n",
    "    \"\"\"Plot the 2D latent space for different conditions\"\"\"\n",
    "    conditions_onehot = labels_to_onehot(labels, cvae.num_classes)\n",
    "    \n",
    "    # Encode to latent space\n",
    "    z_mean, _ = cvae.encoder([data, conditions_onehot])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "    \n",
    "    for class_id in range(cvae.num_classes):\n",
    "        mask = labels == class_id\n",
    "        plt.scatter(z_mean[mask, 0], z_mean[mask, 1], \n",
    "                   c=colors[class_id], label=f'Class {class_id}', alpha=0.6)\n",
    "    \n",
    "    plt.xlabel(\"Latent Dimension 1\")\n",
    "    plt.ylabel(\"Latent Dimension 2\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def plot_conditional_reconstructions(cvae, data, labels, n_samples=5):\n",
    "    \"\"\"Plot original vs reconstructed vectors for each class\"\"\"\n",
    "    fig, axes = plt.subplots(2 * cvae.num_classes, n_samples, \n",
    "                            figsize=(15, 4 * cvae.num_classes))\n",
    "    \n",
    "    for class_id in range(cvae.num_classes):\n",
    "        # Get samples from this class\n",
    "        class_mask = labels == class_id\n",
    "        class_data = data[class_mask]\n",
    "        class_labels = labels[class_mask]\n",
    "        \n",
    "        if len(class_data) < n_samples:\n",
    "            continue\n",
    "            \n",
    "        indices = np.random.choice(len(class_data), n_samples, replace=False)\n",
    "        x_sample = class_data[indices]\n",
    "        y_sample = class_labels[indices]\n",
    "        \n",
    "        conditions_onehot = labels_to_onehot(y_sample, cvae.num_classes)\n",
    "        reconstructions, _, _ = cvae([x_sample, conditions_onehot])\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            row_orig = class_id * 2\n",
    "            row_recon = class_id * 2 + 1\n",
    "            \n",
    "            # Original\n",
    "            axes[row_orig, i].bar(range(9), x_sample[i])\n",
    "            axes[row_orig, i].set_title(f\"Class {class_id} - Original {i+1}\")\n",
    "            axes[row_orig, i].set_ylim(0, 1)\n",
    "            axes[row_orig, i].set_xticks(range(9))\n",
    "            \n",
    "            # Reconstruction\n",
    "            axes[row_recon, i].bar(range(9), reconstructions[i])\n",
    "            axes[row_recon, i].set_title(f\"Class {class_id} - Reconstructed {i+1}\")\n",
    "            axes[row_recon, i].set_ylim(0, 1)\n",
    "            axes[row_recon, i].set_xticks(range(9))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_conditional_samples(cvae, n_samples_per_class=3):\n",
    "    \"\"\"Generate new samples for each condition\"\"\"\n",
    "    fig, axes = plt.subplots(cvae.num_classes, n_samples_per_class, \n",
    "                            figsize=(12, 3 * cvae.num_classes))\n",
    "    \n",
    "    for class_id in range(cvae.num_classes):\n",
    "        # Create condition vector for this class\n",
    "        conditions = np.zeros((n_samples_per_class, cvae.num_classes))\n",
    "        conditions[:, class_id] = 1  # One-hot encoding\n",
    "        conditions = tf.constant(conditions, dtype=tf.float32)\n",
    "        \n",
    "        # Sample random latent vectors\n",
    "        random_latent = tf.random.normal(shape=(n_samples_per_class, cvae.latent_dim))\n",
    "        \n",
    "        # Generate samples\n",
    "        generated_samples = cvae.decode(random_latent, conditions)\n",
    "        \n",
    "        for i in range(n_samples_per_class):\n",
    "            if cvae.num_classes == 1:\n",
    "                ax = axes[i]\n",
    "            else:\n",
    "                ax = axes[class_id, i]\n",
    "                \n",
    "            ax.bar(range(9), generated_samples[i])\n",
    "            ax.set_title(f\"Class {class_id} - Generated {i+1}\")\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.set_xticks(range(9))\n",
    "    \n",
    "    plt.suptitle(\"Generated Samples by Condition\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def interpolate_between_conditions(cvae, data, labels):\n",
    "    \"\"\"Interpolate between different conditions in latent space\"\"\"\n",
    "    # Get one sample from each class\n",
    "    samples_by_class = []\n",
    "    for class_id in range(cvae.num_classes):\n",
    "        class_mask = labels == class_id\n",
    "        class_data = data[class_mask]\n",
    "        if len(class_data) > 0:\n",
    "            samples_by_class.append(class_data[0:1])  # Take first sample\n",
    "    \n",
    "    if len(samples_by_class) < 2:\n",
    "        print(\"Need at least 2 classes for interpolation\")\n",
    "        return\n",
    "    \n",
    "    # Encode samples to latent space\n",
    "    latent_codes = []\n",
    "    for i, sample in enumerate(samples_by_class):\n",
    "        condition = np.zeros((1, cvae.num_classes))\n",
    "        condition[0, i] = 1\n",
    "        condition = tf.constant(condition, dtype=tf.float32)\n",
    "        \n",
    "        z_mean, _ = cvae.encoder([sample, condition])\n",
    "        latent_codes.append(z_mean)\n",
    "    \n",
    "    # Interpolate between first two classes\n",
    "    z1, z2 = latent_codes[0], latent_codes[1]\n",
    "    n_steps = 5\n",
    "    alphas = np.linspace(0, 1, n_steps)\n",
    "    \n",
    "    # Create conditions for interpolation (gradually change from class 0 to class 1)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    for i, alpha in enumerate(alphas):\n",
    "        # Interpolate latent code\n",
    "        z_interp = (1 - alpha) * z1 + alpha * z2\n",
    "        \n",
    "        # Interpolate condition (gradually change from class 0 to class 1)\n",
    "        condition = np.array([[1-alpha, alpha] + [0] * (cvae.num_classes-2)])\n",
    "        condition = tf.constant(condition, dtype=tf.float32)\n",
    "        \n",
    "        # Generate sample\n",
    "        generated = cvae.decode(z_interp, condition)\n",
    "        \n",
    "        plt.subplot(1, n_steps, i + 1)\n",
    "        plt.bar(range(9), generated[0])\n",
    "        plt.title(f\"α = {alpha:.2f}\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xticks(range(9))\n",
    "    \n",
    "    plt.suptitle(\"Interpolation Between Conditions\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_cvae_summary(cvae):\n",
    "    \"\"\"Print CVAE architecture summary\"\"\"\n",
    "    print(\"CVAE Architecture:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Input dimension: {cvae.input_dim}\")\n",
    "    print(f\"Hidden dimension: {cvae.hidden_dim}\")\n",
    "    print(f\"Latent dimension: {cvae.latent_dim}\")\n",
    "    print(f\"Number of classes: {cvae.num_classes}\")\n",
    "    print(\"\\nEncoder (takes data + condition):\")\n",
    "    cvae.encoder.summary()\n",
    "    print(\"\\nDecoder (takes latent + condition):\")\n",
    "    cvae.decoder.summary()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate conditional synthetic data\n",
    "    print(\"Generating synthetic conditional 9D data...\")\n",
    "    num_classes = 3\n",
    "    data, labels = generate_conditional_synthetic_data(n_samples=1800, num_classes=num_classes)\n",
    "    \n",
    "    # Split into train/test\n",
    "    train_size = int(0.8 * len(data))\n",
    "    x_train, x_test = data[:train_size], data[train_size:]\n",
    "    y_train, y_test = labels[:train_size], labels[train_size:]\n",
    "    \n",
    "    # Convert labels to one-hot\n",
    "    y_train_onehot = labels_to_onehot(y_train, num_classes)\n",
    "    y_test_onehot = labels_to_onehot(y_test, num_classes)\n",
    "    \n",
    "    # Create dataset\n",
    "    batch_size = 64\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train_onehot))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "    \n",
    "    # Create CVAE\n",
    "    cvae = CVAE(input_dim=9, hidden_dim=7, latent_dim=2, num_classes=num_classes)\n",
    "    print_cvae_summary(cvae)\n",
    "    \n",
    "    # Train CVAE\n",
    "    trainer = CVAETrainer(cvae)\n",
    "    print(\"\\nTraining CVAE...\")\n",
    "    trainer.train(train_dataset, epochs=100)\n",
    "    \n",
    "    # Visualizations\n",
    "    print(\"\\nPlotting conditional reconstructions...\")\n",
    "    plot_conditional_reconstructions(cvae, x_test, y_test)\n",
    "    \n",
    "    print(\"Generating conditional samples...\")\n",
    "    generate_conditional_samples(cvae)\n",
    "    \n",
    "    print(\"Plotting conditional latent space...\")\n",
    "    plot_conditional_latent_space(cvae, x_test, y_test)\n",
    "    \n",
    "    print(\"Interpolating between conditions...\")\n",
    "    interpolate_between_conditions(cvae, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LSTM Autoencoder for anomaly detection in multidimensional time series\n",
    "Base case: 7 input dimensions, latent space = 3\n",
    "TensorFlow 2 / Keras implementation.\n",
    "\n",
    "Features:\n",
    "- Model definition (encoder, decoder)\n",
    "- Synthetic data generator with injected anomalies\n",
    "- Training pipeline with early stopping\n",
    "- Reconstruction error-based anomaly scoring and thresholding\n",
    "- Simple evaluation and plotting\n",
    "\n",
    "Run as a script or import functions for experimentation.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# Config / Hyperparameters\n",
    "# -------------------------\n",
    "TIMESTEPS = 50            # length of each sequence window\n",
    "N_FEATURES = 7            # dimensionality of input (user requested base case)\n",
    "LATENT_DIM = 3            # size of the bottleneck (user requested)\n",
    "LSTM_UNITS = 64          # units in LSTM layers\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# -------------------------\n",
    "# Model: LSTM Autoencoder\n",
    "# -------------------------\n",
    "\n",
    "def build_lstm_autoencoder(timesteps=TIMESTEPS, n_features=N_FEATURES,\n",
    "                           latent_dim=LATENT_DIM, lstm_units=LSTM_UNITS):\n",
    "    \"\"\"Builds a sequence-to-sequence LSTM autoencoder.\n",
    "\n",
    "    Encoder:\n",
    "      - LSTM (returns final state) -> Dense latent\n",
    "\n",
    "    Decoder:\n",
    "      - RepeatVector -> LSTM (return sequences) -> TimeDistributed(Dense(n_features))\n",
    "\n",
    "    Returns: compiled Keras model and an encoder model (for latent extraction)\n",
    "    \"\"\"\n",
    "    # Encoder\n",
    "    encoder_inputs = layers.Input(shape=(timesteps, n_features), name=\"encoder_input\")\n",
    "    x = layers.LSTM(lstm_units, return_sequences=False, name=\"enc_lstm_1\")(encoder_inputs)\n",
    "    latent = layers.Dense(latent_dim, activation=\"linear\", name=\"latent_vector\")(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.RepeatVector(timesteps, name=\"repeat_vector\")(latent)\n",
    "    x = layers.LSTM(lstm_units, return_sequences=True, name=\"dec_lstm_1\")(x)\n",
    "    decoder_outputs = layers.TimeDistributed(layers.Dense(n_features), name=\"decoder_output\")(x)\n",
    "\n",
    "    autoencoder = models.Model(encoder_inputs, decoder_outputs, name=\"lstm_autoencoder\")\n",
    "\n",
    "    # also create encoder model for latent extraction\n",
    "    encoder_model = models.Model(encoder_inputs, latent, name=\"encoder_model\")\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "    return autoencoder, encoder_model\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Synthetic Data Generator\n",
    "# -------------------------\n",
    "\n",
    "def generate_synthetic_data(n_samples=5000, timesteps=TIMESTEPS, n_features=N_FEATURES,\n",
    "                            anomaly_fraction=0.02, anomaly_magnitude=5.0):\n",
    "    \"\"\"Generate multivariate time series windows with some injected anomalies.\n",
    "\n",
    "    Returns: X (n_samples, timesteps, n_features), y (binary labels per window: 0 normal, 1 anomaly)\n",
    "    \"\"\"\n",
    "    # base normal signals: mixture of sinusoids + gaussian noise per feature\n",
    "    t = np.linspace(0, 2 * np.pi, timesteps)\n",
    "    X = np.zeros((n_samples, timesteps, n_features), dtype=np.float32)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        for f in range(n_features):\n",
    "            freq = 0.5 + 0.5 * (f + 1) / n_features\n",
    "            phase = np.random.RandomState(SEED + i + f).rand() * 2 * np.pi\n",
    "            amp = 1.0 + 0.1 * f\n",
    "            signal = amp * np.sin(freq * t + phase)\n",
    "            noise = 0.1 * np.random.normal(size=timesteps)\n",
    "            X[i, :, f] = signal + noise\n",
    "\n",
    "    # labels\n",
    "    y = np.zeros((n_samples,), dtype=int)\n",
    "\n",
    "    # inject anomalies into a fraction of windows\n",
    "    n_anom = int(n_samples * anomaly_fraction)\n",
    "    anomaly_indices = np.random.choice(n_samples, size=n_anom, replace=False)\n",
    "    for idx in anomaly_indices:\n",
    "        # choose random feature(s) and random time segments to corrupt\n",
    "        n_corrupt_features = np.random.randint(1, n_features // 2 + 1)\n",
    "        corrupt_features = np.random.choice(n_features, size=n_corrupt_features, replace=False)\n",
    "        start = np.random.randint(0, timesteps // 2)\n",
    "        length = np.random.randint(timesteps // 8, timesteps // 2)\n",
    "        end = min(timesteps, start + length)\n",
    "        for f in corrupt_features:\n",
    "            # add a large offset and scaled noise\n",
    "            X[idx, start:end, f] += anomaly_magnitude * (np.random.randn(end - start) + 3.0)\n",
    "        y[idx] = 1\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utility: compute reconstruction errors and threshold\n",
    "# -------------------------\n",
    "\n",
    "def reconstruction_errors(model, X):\n",
    "    \"\"\"Return per-window MSE reconstruction error (mean over timesteps and features)\n",
    "    and also the per-timestep/per-feature error if desired.\n",
    "    \"\"\"\n",
    "    X_pred = model.predict(X, verbose=0)\n",
    "    se = np.mean(np.square(X - X_pred), axis=(1, 2))  # MSE per-window\n",
    "    return se\n",
    "\n",
    "\n",
    "def choose_threshold(errors, method=\"percentile\", percentile=99.0):\n",
    "    \"\"\"Choose an anomaly threshold from reconstruction errors. Methods supported:\n",
    "    - percentile: use a high percentile of the training errors\n",
    "    - std: mean + k * std\n",
    "    \"\"\"\n",
    "    if method == \"percentile\":\n",
    "        thresh = np.percentile(errors, percentile)\n",
    "    elif method == \"std\":\n",
    "        thresh = errors.mean() + 3.0 * errors.std()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "    return thresh\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Example training + detection\n",
    "# -------------------------\n",
    "\n",
    "def example_run():\n",
    "    # Generate data\n",
    "    X, y = generate_synthetic_data(n_samples=5000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "    # We'll train only on *normal* windows (y == 0)\n",
    "    X_train_norm = X_train[y_train == 0]\n",
    "    print(f\"Training on {len(X_train_norm)} normal windows (out of {len(X_train)})\")\n",
    "\n",
    "    # Build model\n",
    "    autoencoder, encoder = build_lstm_autoencoder()\n",
    "    autoencoder.summary()\n",
    "\n",
    "    # Callbacks\n",
    "    es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "    history = autoencoder.fit(\n",
    "        X_train_norm, X_train_norm,\n",
    "        validation_split=0.1,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[es],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Compute reconstruction errors on train-normal (used to set threshold)\n",
    "    train_errors = reconstruction_errors(autoencoder, X_train_norm)\n",
    "    thresh = choose_threshold(train_errors, method=\"percentile\", percentile=99.5)\n",
    "    print(f\"Chosen threshold (99.5 percentile of train normal errors): {thresh:.6f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_errors = reconstruction_errors(autoencoder, X_test)\n",
    "    y_pred = (test_errors >= thresh).astype(int)\n",
    "\n",
    "    # Basic metrics\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(\"Confusion matrix (test set):\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    # Plot example errors and threshold\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(test_errors, label=\"reconstruction_error\")\n",
    "    plt.hlines(thresh, xmin=0, xmax=len(test_errors)-1, colors=\"r\", linestyles=\"dashed\", label=\"threshold\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Reconstruction errors on test set\")\n",
    "    plt.xlabel(\"window index\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.show()\n",
    "\n",
    "    # Show some examples of reconstructed sequences\n",
    "    n_examples = 3\n",
    "    idxs = np.random.choice(len(X_test), size=n_examples, replace=False)\n",
    "    X_pred = autoencoder.predict(X_test[idxs])\n",
    "\n",
    "    for i, idx in enumerate(idxs):\n",
    "        fig, axes = plt.subplots(N_FEATURES, 1, figsize=(10, 2 * N_FEATURES), sharex=True)\n",
    "        fig.suptitle(f\"Window idx {idx} - label={y_test[idx]} - error={test_errors[idx]:.6f}\")\n",
    "        for f in range(N_FEATURES):\n",
    "            axes[f].plot(X_test[idx][:, f], label=\"orig\")\n",
    "            axes[f].plot(X_pred[i][:, f], label=\"recon\", linestyle=\"--\")\n",
    "            axes[f].legend(loc=\"upper right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return autoencoder, encoder, thresh\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LSTM Autoencoder for anomaly detection in multidimensional time series\n",
    "Base case: 7 input dimensions, latent space = 3\n",
    "TensorFlow 2 / Keras implementation with clean subclassed model API.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# Config / Hyperparameters\n",
    "# -------------------------\n",
    "TIMESTEPS = 50\n",
    "N_FEATURES = 7\n",
    "LATENT_DIM = 3\n",
    "LSTM_UNITS = 64\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# -------------------------\n",
    "# Model: Subclassed LSTM Autoencoder\n",
    "# -------------------------\n",
    "class LSTMAutoencoder(tf.keras.Model):\n",
    "    def __init__(self, timesteps, n_features, latent_dim, lstm_units):\n",
    "        super().__init__()\n",
    "        self.encoder_lstm = layers.LSTM(lstm_units, return_sequences=False, name=\"enc_lstm\")\n",
    "        self.latent_dense = layers.Dense(latent_dim, activation=\"linear\", name=\"latent\")\n",
    "        self.repeat_vector = layers.RepeatVector(timesteps, name=\"repeat\")\n",
    "        self.decoder_lstm = layers.LSTM(lstm_units, return_sequences=True, name=\"dec_lstm\")\n",
    "        self.decoder_output = layers.TimeDistributed(layers.Dense(n_features), name=\"output\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.encoder_lstm(inputs)\n",
    "        latent = self.latent_dense(x)\n",
    "        x = self.repeat_vector(latent)\n",
    "        x = self.decoder_lstm(x)\n",
    "        return self.decoder_output(x)\n",
    "\n",
    "# -------------------------\n",
    "# Synthetic Data Generator\n",
    "# -------------------------\n",
    "\n",
    "def generate_synthetic_data(n_samples=5000, timesteps=TIMESTEPS, n_features=N_FEATURES,\n",
    "                            anomaly_fraction=0.02, anomaly_magnitude=5.0):\n",
    "    t = np.linspace(0, 2 * np.pi, timesteps)\n",
    "    X = np.zeros((n_samples, timesteps, n_features), dtype=np.float32)\n",
    "    for i in range(n_samples):\n",
    "        for f in range(n_features):\n",
    "            freq = 0.5 + 0.5 * (f + 1) / n_features\n",
    "            phase = np.random.RandomState(SEED + i + f).rand() * 2 * np.pi\n",
    "            amp = 1.0 + 0.1 * f\n",
    "            signal = amp * np.sin(freq * t + phase)\n",
    "            noise = 0.1 * np.random.normal(size=timesteps)\n",
    "            X[i, :, f] = signal + noise\n",
    "    y = np.zeros((n_samples,), dtype=int)\n",
    "    n_anom = int(n_samples * anomaly_fraction)\n",
    "    anomaly_indices = np.random.choice(n_samples, size=n_anom, replace=False)\n",
    "    for idx in anomaly_indices:\n",
    "        n_corrupt_features = np.random.randint(1, n_features // 2 + 1)\n",
    "        corrupt_features = np.random.choice(n_features, size=n_corrupt_features, replace=False)\n",
    "        start = np.random.randint(0, timesteps // 2)\n",
    "        length = np.random.randint(timesteps // 8, timesteps // 2)\n",
    "        end = min(timesteps, start + length)\n",
    "        for f in corrupt_features:\n",
    "            X[idx, start:end, f] += anomaly_magnitude * (np.random.randn(end - start) + 3.0)\n",
    "        y[idx] = 1\n",
    "    return X, y\n",
    "\n",
    "# -------------------------\n",
    "# Utility\n",
    "# -------------------------\n",
    "\n",
    "def reconstruction_errors(model, X):\n",
    "    X_pred = model.predict(X, verbose=0)\n",
    "    return np.mean(np.square(X - X_pred), axis=(1, 2))\n",
    "\n",
    "def choose_threshold(errors, percentile=99.0):\n",
    "    return np.percentile(errors, percentile)\n",
    "\n",
    "# -------------------------\n",
    "# Example run\n",
    "# -------------------------\n",
    "\n",
    "def example_run():\n",
    "    X, y = generate_synthetic_data(n_samples=5000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "    X_train_norm = X_train[y_train == 0]\n",
    "\n",
    "    autoencoder = LSTMAutoencoder(TIMESTEPS, N_FEATURES, LATENT_DIM, LSTM_UNITS)\n",
    "    optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "    es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "    autoencoder.fit(X_train_norm, X_train_norm, validation_split=0.1, epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE, callbacks=[es], verbose=2)\n",
    "\n",
    "    train_errors = reconstruction_errors(autoencoder, X_train_norm)\n",
    "    thresh = choose_threshold(train_errors, percentile=99.5)\n",
    "    print(f\"Chosen threshold: {thresh:.6f}\")\n",
    "\n",
    "    test_errors = reconstruction_errors(autoencoder, X_test)\n",
    "    y_pred = (test_errors >= thresh).astype(int)\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(test_errors, label=\"reconstruction_error\")\n",
    "    plt.hlines(thresh, 0, len(test_errors)-1, colors=\"r\", linestyles=\"dashed\", label=\"threshold\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7291e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class LSTMAutoencoder:\n",
    "    \"\"\"\n",
    "    LSTM Autoencoder for multivariate time series anomaly detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=7, latent_dim=3, sequence_length=10, \n",
    "                 lstm_units=64, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Initialize LSTM Autoencoder\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Number of features in input data\n",
    "            latent_dim: Dimension of latent/encoded representation\n",
    "            sequence_length: Length of input sequences\n",
    "            lstm_units: Number of LSTM units in encoder/decoder\n",
    "            learning_rate: Learning rate for optimizer\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm_units = lstm_units\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.model = None\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.threshold = None\n",
    "        \n",
    "        self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        \"\"\"Build the LSTM Autoencoder architecture\"\"\"\n",
    "        \n",
    "        # Input layer\n",
    "        input_layer = tf.keras.Input(shape=(self.sequence_length, self.input_dim))\n",
    "        \n",
    "        # Encoder\n",
    "        encoded = tf.keras.layers.LSTM(self.lstm_units, return_sequences=True, \n",
    "                                     name='encoder_lstm1')(input_layer)\n",
    "        encoded = tf.keras.layers.Dropout(0.2)(encoded)\n",
    "        encoded = tf.keras.layers.LSTM(self.lstm_units//2, return_sequences=False, \n",
    "                                     name='encoder_lstm2')(encoded)\n",
    "        \n",
    "        # Bottleneck (latent representation)\n",
    "        latent = tf.keras.layers.Dense(self.latent_dim, activation='tanh', \n",
    "                                     name='latent_layer')(encoded)\n",
    "        \n",
    "        # Decoder\n",
    "        decoded = tf.keras.layers.RepeatVector(self.sequence_length)(latent)\n",
    "        decoded = tf.keras.layers.LSTM(self.lstm_units//2, return_sequences=True, \n",
    "                                     name='decoder_lstm1')(decoded)\n",
    "        decoded = tf.keras.layers.Dropout(0.2)(decoded)\n",
    "        decoded = tf.keras.layers.LSTM(self.lstm_units, return_sequences=True, \n",
    "                                     name='decoder_lstm2')(decoded)\n",
    "        \n",
    "        # Output layer\n",
    "        output_layer = tf.keras.layers.TimeDistributed(\n",
    "            tf.keras.layers.Dense(self.input_dim, activation='linear'),\n",
    "            name='output_layer'\n",
    "        )(decoded)\n",
    "        \n",
    "        # Create models\n",
    "        self.model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "        self.encoder = tf.keras.Model(inputs=input_layer, outputs=latent)\n",
    "        \n",
    "        # Compile model\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "    \n",
    "    def prepare_sequences(self, data):\n",
    "        \"\"\"\n",
    "        Prepare sequences for LSTM input\n",
    "        \n",
    "        Args:\n",
    "            data: Input data of shape (samples, features)\n",
    "            \n",
    "        Returns:\n",
    "            sequences: Array of shape (num_sequences, sequence_length, features)\n",
    "        \"\"\"\n",
    "        sequences = []\n",
    "        for i in range(len(data) - self.sequence_length + 1):\n",
    "            sequences.append(data[i:i + self.sequence_length])\n",
    "        return np.array(sequences)\n",
    "    \n",
    "    def preprocess_data(self, X, fit_scaler=True):\n",
    "        \"\"\"\n",
    "        Preprocess data: normalize and create sequences\n",
    "        \n",
    "        Args:\n",
    "            X: Input data\n",
    "            fit_scaler: Whether to fit the scaler (True for training data)\n",
    "            \n",
    "        Returns:\n",
    "            X_processed: Preprocessed sequences\n",
    "        \"\"\"\n",
    "        if fit_scaler:\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        X_sequences = self.prepare_sequences(X_scaled)\n",
    "        return X_sequences\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, x_batch):\n",
    "        \"\"\"\n",
    "        Custom training step for the autoencoder\n",
    "        \n",
    "        Args:\n",
    "            x_batch: Batch of input sequences\n",
    "            \n",
    "        Returns:\n",
    "            loss: Training loss for the batch\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            reconstructed = self.model(x_batch, training=True)\n",
    "            # Compute loss\n",
    "            loss = tf.keras.losses.mse(x_batch, reconstructed)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        # Apply gradients\n",
    "        self.model.optimizer.apply_gradients(\n",
    "            zip(gradients, self.model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def fit(self, X_train, epochs=100, batch_size=32, validation_split=0.2, \n",
    "            verbose=1, early_stopping_patience=10):\n",
    "        \"\"\"\n",
    "        Train the LSTM Autoencoder\n",
    "        \n",
    "        Args:\n",
    "            X_train: Training data\n",
    "            epochs: Number of training epochs\n",
    "            batch_size: Batch size for training\n",
    "            validation_split: Fraction of data to use for validation\n",
    "            verbose: Verbosity level\n",
    "            early_stopping_patience: Patience for early stopping\n",
    "            \n",
    "        Returns:\n",
    "            history: Training history\n",
    "        \"\"\"\n",
    "        print(f\"Preprocessing training data...\")\n",
    "        X_train_processed = self.preprocess_data(X_train, fit_scaler=True)\n",
    "        print(f\"Training sequences shape: {X_train_processed.shape}\")\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=early_stopping_patience,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-7\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Train the model\n",
    "        history = self.model.fit(\n",
    "            X_train_processed, X_train_processed,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=validation_split,\n",
    "            callbacks=callbacks,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def calculate_reconstruction_error(self, X):\n",
    "        \"\"\"\n",
    "        Calculate reconstruction error for anomaly detection\n",
    "        \n",
    "        Args:\n",
    "            X: Input data\n",
    "            \n",
    "        Returns:\n",
    "            errors: Reconstruction errors for each sequence\n",
    "        \"\"\"\n",
    "        X_processed = self.preprocess_data(X, fit_scaler=False)\n",
    "        reconstructed = self.model.predict(X_processed, verbose=0)\n",
    "        \n",
    "        # Calculate MSE for each sequence\n",
    "        errors = np.mean(np.square(X_processed - reconstructed), axis=(1, 2))\n",
    "        return errors\n",
    "    \n",
    "    def set_threshold(self, X_normal, percentile=95):\n",
    "        \"\"\"\n",
    "        Set anomaly detection threshold based on normal data\n",
    "        \n",
    "        Args:\n",
    "            X_normal: Normal (non-anomalous) data\n",
    "            percentile: Percentile to use as threshold\n",
    "        \"\"\"\n",
    "        errors = self.calculate_reconstruction_error(X_normal)\n",
    "        self.threshold = np.percentile(errors, percentile)\n",
    "        print(f\"Anomaly threshold set to: {self.threshold:.6f}\")\n",
    "    \n",
    "    def predict_anomalies(self, X):\n",
    "        \"\"\"\n",
    "        Predict anomalies in the input data\n",
    "        \n",
    "        Args:\n",
    "            X: Input data to check for anomalies\n",
    "            \n",
    "        Returns:\n",
    "            predictions: Binary predictions (1 for anomaly, 0 for normal)\n",
    "            errors: Reconstruction errors\n",
    "        \"\"\"\n",
    "        if self.threshold is None:\n",
    "            raise ValueError(\"Threshold not set. Call set_threshold() first.\")\n",
    "        \n",
    "        errors = self.calculate_reconstruction_error(X)\n",
    "        predictions = (errors > self.threshold).astype(int)\n",
    "        \n",
    "        return predictions, errors\n",
    "    \n",
    "    def encode(self, X):\n",
    "        \"\"\"\n",
    "        Encode input data to latent representation\n",
    "        \n",
    "        Args:\n",
    "            X: Input data\n",
    "            \n",
    "        Returns:\n",
    "            latent_repr: Encoded latent representations\n",
    "        \"\"\"\n",
    "        X_processed = self.preprocess_data(X, fit_scaler=False)\n",
    "        latent_repr = self.encoder.predict(X_processed, verbose=0)\n",
    "        return latent_repr\n",
    "    \n",
    "    def plot_training_history(self, history):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(history.history['loss'], label='Training Loss')\n",
    "        ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        ax1.set_title('Model Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # MAE plot\n",
    "        ax2.plot(history.history['mae'], label='Training MAE')\n",
    "        ax2.plot(history.history['val_mae'], label='Validation MAE')\n",
    "        ax2.set_title('Model MAE')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('MAE')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_reconstruction_error(self, errors_normal, errors_anomaly=None):\n",
    "        \"\"\"Plot reconstruction error distribution\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        plt.hist(errors_normal, bins=50, alpha=0.7, label='Normal', density=True)\n",
    "        if errors_anomaly is not None:\n",
    "            plt.hist(errors_anomaly, bins=50, alpha=0.7, label='Anomaly', density=True)\n",
    "        \n",
    "        if self.threshold is not None:\n",
    "            plt.axvline(x=self.threshold, color='red', linestyle='--', \n",
    "                       label=f'Threshold: {self.threshold:.4f}')\n",
    "        \n",
    "        plt.xlabel('Reconstruction Error')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title('Distribution of Reconstruction Errors')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Example usage and testing\n",
    "def generate_sample_data():\n",
    "    \"\"\"Generate sample multivariate time series data with anomalies\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Normal data: sinusoidal patterns with some noise\n",
    "    n_samples = 1000\n",
    "    time = np.linspace(0, 50, n_samples)\n",
    "    \n",
    "    normal_data = np.zeros((n_samples, 7))\n",
    "    for i in range(7):\n",
    "        freq = 0.1 + i * 0.05\n",
    "        phase = i * np.pi / 4\n",
    "        normal_data[:, i] = np.sin(2 * np.pi * freq * time + phase) + \\\n",
    "                           0.1 * np.random.randn(n_samples)\n",
    "    \n",
    "    # Anomalous data: sudden spikes and different patterns\n",
    "    n_anomalies = 100\n",
    "    anomaly_data = np.zeros((n_anomalies, 7))\n",
    "    time_anom = np.linspace(0, 5, n_anomalies)\n",
    "    \n",
    "    for i in range(7):\n",
    "        # Create anomalies with different patterns\n",
    "        if i < 3:\n",
    "            # Spikes\n",
    "            anomaly_data[:, i] = 3 * np.random.randn(n_anomalies)\n",
    "        else:\n",
    "            # Different frequency patterns\n",
    "            anomaly_data[:, i] = 2 * np.sin(10 * time_anom + i) + \\\n",
    "                               0.5 * np.random.randn(n_anomalies)\n",
    "    \n",
    "    return normal_data, anomaly_data\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function demonstrating LSTM-AE usage\"\"\"\n",
    "    print(\"LSTM Autoencoder for Anomaly Detection\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Generate sample data\n",
    "    print(\"1. Generating sample data...\")\n",
    "    normal_data, anomaly_data = generate_sample_data()\n",
    "    print(f\"Normal data shape: {normal_data.shape}\")\n",
    "    print(f\"Anomaly data shape: {anomaly_data.shape}\")\n",
    "    \n",
    "    # Split normal data for training and testing\n",
    "    split_idx = int(0.8 * len(normal_data))\n",
    "    X_train = normal_data[:split_idx]\n",
    "    X_test_normal = normal_data[split_idx:]\n",
    "    \n",
    "    # Initialize LSTM Autoencoder\n",
    "    print(\"\\n2. Initializing LSTM Autoencoder...\")\n",
    "    lstm_ae = LSTMAutoencoder(\n",
    "        input_dim=7,\n",
    "        latent_dim=3,\n",
    "        sequence_length=10,\n",
    "        lstm_units=64,\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "    \n",
    "    print(f\"Model architecture:\")\n",
    "    lstm_ae.model.summary()\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"\\n3. Training the model...\")\n",
    "    history = lstm_ae.fit(\n",
    "        X_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=1,\n",
    "        early_stopping_patience=10\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    print(\"\\n4. Plotting training history...\")\n",
    "    lstm_ae.plot_training_history(history)\n",
    "    \n",
    "    # Set anomaly detection threshold\n",
    "    print(\"\\n5. Setting anomaly detection threshold...\")\n",
    "    lstm_ae.set_threshold(X_test_normal, percentile=95)\n",
    "    \n",
    "    # Test on normal data\n",
    "    print(\"\\n6. Testing on normal data...\")\n",
    "    pred_normal, errors_normal = lstm_ae.predict_anomalies(X_test_normal)\n",
    "    print(f\"Normal data - Anomalies detected: {np.sum(pred_normal)}/{len(pred_normal)}\")\n",
    "    \n",
    "    # Test on anomalous data\n",
    "    print(\"\\n7. Testing on anomalous data...\")\n",
    "    pred_anomaly, errors_anomaly = lstm_ae.predict_anomalies(anomaly_data)\n",
    "    print(f\"Anomalous data - Anomalies detected: {np.sum(pred_anomaly)}/{len(pred_anomaly)}\")\n",
    "    \n",
    "    # Plot reconstruction error distributions\n",
    "    print(\"\\n8. Plotting reconstruction error distributions...\")\n",
    "    lstm_ae.plot_reconstruction_error(errors_normal, errors_anomaly)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    print(\"\\n9. Performance Evaluation:\")\n",
    "    y_true = np.concatenate([np.zeros(len(pred_normal)), np.ones(len(pred_anomaly))])\n",
    "    y_pred = np.concatenate([pred_normal, pred_anomaly])\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    # Test encoding functionality\n",
    "    print(\"\\n10. Testing latent encoding...\")\n",
    "    latent_repr = lstm_ae.encode(X_test_normal[:5])\n",
    "    print(f\"Original data shape: {X_test_normal[:5].shape}\")\n",
    "    print(f\"Latent representation shape: {latent_repr.shape}\")\n",
    "    print(f\"Sample latent vectors:\\n{latent_repr}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
